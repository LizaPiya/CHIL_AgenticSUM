{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8381f248-89ef-499c-b2eb-315d171c5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers huggingface_hub\n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3009b7f-64e7-4cd3-b735-1cc780a0dd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/fsspec/registry.py:294: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>target_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16002318-DS-17</td>\n",
       "      <td>&lt;SEX&gt; F &lt;SERVICE&gt; SURGERY &lt;ALLERGIES&gt; Iodine /...</td>\n",
       "      <td>This is a ___ yo F admitted to the hospital af...</td>\n",
       "      <td>1195</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          note_id                                              input  \\\n",
       "0  16002318-DS-17  <SEX> F <SERVICE> SURGERY <ALLERGIES> Iodine /...   \n",
       "\n",
       "                                              target  input_tokens  \\\n",
       "0  This is a ___ yo F admitted to the hospital af...          1195   \n",
       "\n",
       "   target_tokens  \n",
       "0             75  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the bucket and file names\n",
    "bucket_name = 'agentsum'  # Replace with your bucket name\n",
    "mimic_iv_bhc = f's3://{bucket_name}/sample_data_100.csv'\n",
    "\n",
    "# Load the files\n",
    "mimic_iv_bhc_100 = pd.read_csv(mimic_iv_bhc)\n",
    "\n",
    "# Display the data\n",
    "mimic_iv_bhc_100.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d935e4ad-ac54-43e0-866c-0872dff0acca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Hugging Face token:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'user', 'id': '6644f24fe7ae8316ebf3fee4', 'name': 'LizaPiya', 'fullname': 'Fahmida Liza Piya', 'email': 'lizapiya@udel.edu', 'emailVerified': True, 'canPay': False, 'periodEnd': None, 'isPro': False, 'avatarUrl': '/avatars/d43d60b3eba464c3f9b44c34e43b64d6.svg', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'Clinical Note LLama', 'role': 'write', 'createdAt': '2024-06-03T19:29:07.142Z'}}}\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from huggingface_hub import whoami\n",
    "import getpass\n",
    "\n",
    "# Prompt the user for the Hugging Face token at runtime\n",
    "hf_token = getpass.getpass(\"Enter your Hugging Face token: \")\n",
    "\n",
    "# Log in using the provided token\n",
    "login(token=hf_token)\n",
    "\n",
    "\n",
    "print(whoami(token=hf_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8dfb4af-9597-4260-99e7-9f12ebc3a4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jax in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.6.2)\n",
      "Requirement already satisfied: jaxlib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.6.2)\n",
      "Requirement already satisfied: flax in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.10.7)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jax) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.26 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jax) (1.26.4)\n",
      "Requirement already satisfied: opt_einsum in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jax) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jax) (1.15.2)\n",
      "Requirement already satisfied: msgpack in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flax) (1.1.1)\n",
      "Requirement already satisfied: optax in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flax) (0.2.5)\n",
      "Requirement already satisfied: orbax-checkpoint in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flax) (0.11.18)\n",
      "Requirement already satisfied: tensorstore in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flax) (0.1.76)\n",
      "Requirement already satisfied: rich>=11.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flax) (14.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flax) (4.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flax) (6.0.2)\n",
      "Requirement already satisfied: treescope>=0.1.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flax) (0.1.9)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich>=11.1->flax) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich>=11.1->flax) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optax->flax) (2.3.1)\n",
      "Requirement already satisfied: chex>=0.1.87 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optax->flax) (0.1.89)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from chex>=0.1.87->optax->flax) (1.0.0)\n",
      "Requirement already satisfied: etils[epath,epy] in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from orbax-checkpoint->flax) (1.12.2)\n",
      "Requirement already satisfied: nest_asyncio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from orbax-checkpoint->flax) (1.6.0)\n",
      "Requirement already satisfied: protobuf in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from orbax-checkpoint->flax) (4.25.3)\n",
      "Requirement already satisfied: humanize in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from orbax-checkpoint->flax) (4.12.3)\n",
      "Requirement already satisfied: simplejson>=3.16.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from orbax-checkpoint->flax) (3.20.1)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (2025.5.1)\n",
      "Requirement already satisfied: importlib_resources in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.5.2)\n",
      "Requirement already satisfied: zipp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.23.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install jax jaxlib flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6301e83b-0542-477e-9479-bed1473853d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa7ffb95e7b44959d95b3237d7399b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5020997d482948c9bb0040b854cf89eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158bf282dae04351a0ac8ded62d3590e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca82e032e46845bc81c857b8aa863c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9e03d81a824374b051fb103529942a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02215d4a511f42fc9fccc44e26cdbf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7135f237be2d4e368787f5bc7b59debf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing entire MIMIC dataset...\n",
      "Total samples to process: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating summaries:   0%|          | 0/100 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:   1%|          | 1/100 [00:10<17:31, 10.62s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:   2%|â–         | 2/100 [00:17<14:02,  8.60s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:   3%|â–Ž         | 3/100 [00:20<09:54,  6.13s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:   4%|â–         | 4/100 [00:26<09:23,  5.87s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:   5%|â–Œ         | 5/100 [00:33<10:03,  6.35s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:   6%|â–Œ         | 6/100 [00:40<10:24,  6.65s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:   7%|â–‹         | 7/100 [00:43<08:19,  5.37s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:   8%|â–Š         | 8/100 [00:50<09:03,  5.91s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:   9%|â–‰         | 9/100 [00:54<07:44,  5.10s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  10%|â–ˆ         | 10/100 [01:01<08:33,  5.71s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  11%|â–ˆ         | 11/100 [01:05<07:52,  5.30s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  12%|â–ˆâ–        | 12/100 [01:12<08:33,  5.84s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  13%|â–ˆâ–Ž        | 13/100 [01:16<07:28,  5.15s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  14%|â–ˆâ–        | 14/100 [01:18<06:12,  4.33s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  15%|â–ˆâ–Œ        | 15/100 [01:21<05:33,  3.92s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  16%|â–ˆâ–Œ        | 16/100 [01:28<06:48,  4.86s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  17%|â–ˆâ–‹        | 17/100 [01:31<06:01,  4.35s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  18%|â–ˆâ–Š        | 18/100 [01:37<06:39,  4.88s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  19%|â–ˆâ–‰        | 19/100 [01:44<07:28,  5.53s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  20%|â–ˆâ–ˆ        | 20/100 [01:50<07:17,  5.46s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  21%|â–ˆâ–ˆ        | 21/100 [01:53<06:28,  4.92s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  22%|â–ˆâ–ˆâ–       | 22/100 [01:56<05:26,  4.19s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  23%|â–ˆâ–ˆâ–Ž       | 23/100 [01:58<04:46,  3.72s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  24%|â–ˆâ–ˆâ–       | 24/100 [02:06<06:00,  4.74s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  25%|â–ˆâ–ˆâ–Œ       | 25/100 [02:13<06:47,  5.44s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  26%|â–ˆâ–ˆâ–Œ       | 26/100 [02:20<07:18,  5.92s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  27%|â–ˆâ–ˆâ–‹       | 27/100 [02:27<07:37,  6.27s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  28%|â–ˆâ–ˆâ–Š       | 28/100 [02:34<07:48,  6.51s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  29%|â–ˆâ–ˆâ–‰       | 29/100 [02:41<07:53,  6.68s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  30%|â–ˆâ–ˆâ–ˆ       | 30/100 [02:48<07:56,  6.80s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [02:55<07:54,  6.88s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [03:02<07:51,  6.93s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [03:05<06:14,  5.60s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [03:07<05:07,  4.66s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [03:14<05:50,  5.39s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [03:18<05:13,  4.90s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [03:21<04:39,  4.43s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [03:28<05:23,  5.22s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [03:33<05:16,  5.20s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [03:38<05:04,  5.07s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [03:42<04:33,  4.63s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [03:49<05:11,  5.37s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [03:51<04:17,  4.52s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [03:59<04:56,  5.29s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [04:06<05:20,  5.82s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [04:13<05:34,  6.20s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [04:20<05:45,  6.52s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [04:27<05:47,  6.69s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [04:34<05:37,  6.62s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [04:37<04:43,  5.67s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [04:44<04:58,  6.09s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [04:50<04:56,  6.17s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [04:53<04:01,  5.13s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [05:00<04:23,  5.72s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [05:07<04:36,  6.14s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [05:12<04:13,  5.75s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [05:19<04:24,  6.15s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [05:26<04:30,  6.43s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [05:33<04:31,  6.63s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [05:36<03:34,  5.37s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [05:43<03:49,  5.88s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [05:50<03:57,  6.24s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [05:52<03:08,  5.08s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [05:59<03:24,  5.68s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [06:07<03:33,  6.10s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [06:14<03:37,  6.40s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [06:20<03:32,  6.43s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [06:27<03:32,  6.63s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [06:34<03:29,  6.77s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [06:41<03:25,  6.86s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [06:44<02:42,  5.59s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [06:47<02:10,  4.66s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [06:54<02:25,  5.39s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [07:01<02:33,  5.89s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [07:06<02:20,  5.60s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [07:13<02:24,  6.02s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [07:20<02:25,  6.34s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [07:27<02:24,  6.57s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [07:33<02:13,  6.36s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [07:36<01:47,  5.36s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [07:41<01:44,  5.48s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [07:45<01:25,  4.77s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [07:48<01:11,  4.23s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [07:55<01:21,  5.09s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [07:58<01:10,  4.71s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [08:05<01:15,  5.37s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [08:12<01:16,  5.88s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [08:20<01:14,  6.24s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [08:27<01:11,  6.50s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [08:34<01:06,  6.69s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [08:37<00:50,  5.59s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [08:44<00:48,  6.04s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [08:48<00:37,  5.36s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [08:55<00:35,  5.88s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [09:02<00:31,  6.25s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [09:06<00:22,  5.64s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [09:08<00:14,  4.68s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [09:14<00:09,  4.84s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [09:21<00:05,  5.52s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating summaries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [09:28<00:00,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All results saved to 'clinical_t5_summaries_full_dataset.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try a different clinical T5 model\n",
    "model_name = \"google/flan-t5-base\"  # General T5 that works well\n",
    "# OR try: \"facebook/bart-large-cnn\" for summarization\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_summary(clinical_note):\n",
    "    prompt = f\"Summarize this clinical note in about 200 words: {clinical_note}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=300,\n",
    "            min_length=100,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    \n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def process_mimic_data(df):\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating summaries\"):\n",
    "        try:\n",
    "            summary = generate_summary(row['input'])\n",
    "            summary_tokens = len(tokenizer.encode(summary))\n",
    "            results.append({\n",
    "                'note_id': row['note_id'],\n",
    "                'original_input': row['input'],\n",
    "                'generated_summary': summary,\n",
    "                'target_summary': row['target'],\n",
    "                'summary_token_count': summary_tokens,\n",
    "                'input_tokens': row['input_tokens'],\n",
    "                'target_tokens': row['target_tokens']\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                'note_id': row['note_id'],\n",
    "                'original_input': row['input'],\n",
    "                'generated_summary': \"ERROR: Could not generate summary\",\n",
    "                'target_summary': row['target'],\n",
    "                'summary_token_count': 0,\n",
    "                'input_tokens': row['input_tokens'],\n",
    "                'target_tokens': row['target_tokens']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run the pipeline\n",
    "print(\"Loading and processing entire MIMIC dataset...\")\n",
    "print(f\"Total samples to process: {len(mimic_iv_bhc_100)}\")\n",
    "full_results = process_mimic_data(mimic_iv_bhc_100)\n",
    "\n",
    "# CHANGE 7: Update filename\n",
    "full_results.to_csv('clinical_t5_summaries_full_dataset.csv', index=False)\n",
    "print(f\"\\nAll results saved to 'clinical_t5_summaries_full_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a978e357-89ab-4a90-a8db-7719d055513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Flan-T5 MIMIC Evaluation\n",
      "================================================================================\n",
      "ðŸ“‚ Loaded 100 samples from Flan_t5_summaries_full_dataset.csv\n",
      "ðŸ“‹ Data columns: ['note_id', 'original_input', 'generated_summary', 'target_summary', 'summary_token_count', 'input_tokens', 'target_tokens']\n",
      "ðŸ“ Data shape: (100, 7)\n",
      "ðŸ“Š Evaluating 100 Flan-T5-generated summaries...\n",
      "ðŸ“ Summary column: generated_summary\n",
      "ðŸŽ¯ Reference column: target_summary\n",
      "\n",
      "ðŸ”¢ Computing BLEU and ROUGE-L scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 70.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  Computing BERTScore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ“Š FLAN-T5 EVALUATION RESULTS\n",
      "================================================================================\n",
      "Metric       Mean Â± Std           Min      Max      Median  \n",
      "----------------------------------------------------------------------\n",
      "BLEU1        4.510 Â± 6.912    0.00     36.62    0.73    \n",
      "BLEU2        2.202 Â± 4.354    0.00     28.83    0.27    \n",
      "ROUGE_L      7.818 Â± 6.860    0.00     34.71    6.62    \n",
      "BERT_P       79.254 Â± 6.512    57.82    89.57    81.20   \n",
      "BERT_R       78.199 Â± 2.945    72.31    89.16    78.17   \n",
      "BERT_F1      78.636 Â± 4.381    64.26    86.82    79.52   \n",
      "\n",
      "================================================================================\n",
      "ðŸ“ˆ BASELINE METRICS SUMMARY (for table)\n",
      "================================================================================\n",
      "BLEU-1: 4.51 Â± 6.91\n",
      "BLEU-2: 2.20 Â± 4.35\n",
      "ROUGE-L: 7.82 Â± 6.86\n",
      "BERTScore-F1: 78.64 Â± 4.38\n",
      "\n",
      "================================================================================\n",
      "ðŸ“ TOKEN LENGTH ANALYSIS\n",
      "================================================================================\n",
      "Generated Summary Tokens:\n",
      "  Mean Â± Std: 199.9 Â± 82.6\n",
      "  Target: 150 tokens\n",
      "  Range: 5 - 300\n",
      "  Within 140-160: 9/100 (9.0%)\n",
      "\n",
      "Target Summary Tokens:\n",
      "  Mean Â± Std: 581.1 Â± 450.6\n",
      "  Range: 18 - 2659\n",
      "\n",
      "ðŸ’¾ Results saved to: Flan_t5_summaries_full_dataset_evaluation_results.csv\n",
      "\n",
      "================================================================================\n",
      "ðŸ“‹ SAMPLE RESULTS\n",
      "================================================================================\n",
      "Note ID: 16002318-DS-17\n",
      "Generated Summary Token Count: 5\n",
      "BLEU-1: 0.00\n",
      "ROUGE-L: 0.00\n",
      "BERTScore-F1: 79.49\n",
      "\n",
      "ðŸŽ‰ Flan-T5 evaluation completed!\n",
      "\n",
      "ðŸ“Š Use these results as baseline metrics for your comparison table!\n"
     ]
    }
   ],
   "source": [
    "%run evaluate_Flan_T5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5269a-f2e7-4d59-8aae-f5c35aa2e69c",
   "metadata": {},
   "source": [
    "### llm as a judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b63651c2-9997-423d-a7f0-0e2155aa6ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Flan-T5 evaluation...\n",
      "ðŸ”„ Loading Llama 3 8B model as judge...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddbbc534a914451eb91a49f7eb0ad71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Loaded 100 Flan-T5 generated summaries\n",
      "ðŸ“‹ Columns: ['note_id', 'original_input', 'generated_summary', 'target_summary', 'summary_token_count', 'input_tokens', 'target_tokens']\n",
      "ðŸ” Evaluating Flan-T5 summaries for hallucinations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:   1%|          | 1/100 [00:05<09:08,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:   2%|â–         | 2/100 [00:10<08:21,  5.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:   3%|â–Ž         | 3/100 [00:16<09:07,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:   4%|â–         | 4/100 [00:20<07:53,  4.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:   5%|â–Œ         | 5/100 [00:26<08:24,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:   6%|â–Œ         | 6/100 [00:31<07:57,  5.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:   7%|â–‹         | 7/100 [00:33<06:16,  4.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:   8%|â–Š         | 8/100 [00:39<07:18,  4.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:   9%|â–‰         | 9/100 [00:41<06:13,  4.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  10%|â–ˆ         | 10/100 [00:45<05:53,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  11%|â–ˆ         | 11/100 [00:48<05:34,  3.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  12%|â–ˆâ–        | 12/100 [00:52<05:15,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  13%|â–ˆâ–Ž        | 13/100 [00:58<06:22,  4.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  14%|â–ˆâ–        | 14/100 [01:04<07:06,  4.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  15%|â–ˆâ–Œ        | 15/100 [01:07<06:12,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  16%|â–ˆâ–Œ        | 16/100 [01:13<06:56,  4.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  17%|â–ˆâ–‹        | 17/100 [01:17<06:04,  4.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  18%|â–ˆâ–Š        | 18/100 [01:23<06:46,  4.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  19%|â–ˆâ–‰        | 19/100 [01:26<05:59,  4.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  20%|â–ˆâ–ˆ        | 20/100 [01:31<05:57,  4.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  21%|â–ˆâ–ˆ        | 21/100 [01:33<05:15,  4.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  22%|â–ˆâ–ˆâ–       | 22/100 [01:40<06:04,  4.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  23%|â–ˆâ–ˆâ–Ž       | 23/100 [01:46<06:36,  5.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  24%|â–ˆâ–ˆâ–       | 24/100 [01:52<06:57,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 25/100 [01:59<07:09,  5.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  26%|â–ˆâ–ˆâ–Œ       | 26/100 [02:05<07:15,  5.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  27%|â–ˆâ–ˆâ–‹       | 27/100 [02:10<06:49,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  28%|â–ˆâ–ˆâ–Š       | 28/100 [02:15<06:41,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  29%|â–ˆâ–ˆâ–‰       | 29/100 [02:21<06:40,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  30%|â–ˆâ–ˆâ–ˆ       | 30/100 [02:27<06:47,  5.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [02:33<06:43,  5.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [02:35<05:13,  4.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [02:38<04:38,  4.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [02:44<05:15,  4.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [02:50<05:24,  5.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [02:56<05:44,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [02:59<04:45,  4.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [03:05<05:10,  5.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [03:08<04:37,  4.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [03:14<05:04,  5.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [03:21<05:20,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [03:22<04:09,  4.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [03:29<04:38,  4.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [03:32<04:05,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [03:38<04:31,  4.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [03:44<04:48,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [03:51<04:58,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [03:53<04:06,  4.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [03:58<04:07,  4.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [04:05<04:23,  5.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [04:11<04:33,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [04:17<04:37,  5.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [04:20<03:52,  4.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [04:24<03:27,  4.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [04:30<03:46,  5.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [04:36<03:58,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [04:43<04:03,  5.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [04:48<03:56,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [04:54<03:59,  5.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [05:01<03:58,  5.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [05:07<03:56,  6.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [05:13<03:52,  6.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [05:19<03:47,  6.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [05:20<02:44,  4.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [05:27<02:57,  5.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [05:33<03:05,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [05:37<02:47,  5.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [05:44<02:54,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [05:50<02:56,  5.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [05:56<02:56,  5.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [06:01<02:40,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [06:06<02:28,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [06:09<02:09,  4.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [06:16<02:16,  5.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [06:22<02:19,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [06:28<02:18,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [06:34<02:16,  5.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [06:41<02:12,  6.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [06:47<02:08,  6.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [06:53<02:03,  6.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [06:59<01:55,  6.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [07:05<01:50,  6.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [07:12<01:45,  6.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [07:18<01:39,  6.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [07:24<01:33,  6.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [07:31<01:27,  6.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [07:37<01:21,  6.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [07:43<01:15,  6.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [07:49<01:08,  6.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [07:56<01:02,  6.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [08:02<00:56,  6.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [08:08<00:50,  6.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [08:14<00:43,  6.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [08:20<00:35,  5.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [08:26<00:30,  6.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [08:29<00:20,  5.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [08:34<00:15,  5.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [08:40<00:10,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [08:47<00:05,  5.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [08:52<00:00,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š FLAN-T5 HALLUCINATION EVALUATION RESULTS:\n",
      "======================================================================\n",
      "Metric                    Mean Â± Std      Min    Max    Perfect Scores\n",
      "----------------------------------------------------------------------\n",
      "Hallucination (1-5)       2.37 Â± 0.80   1.0    5.0    2/100\n",
      "Factual Consistency (1-5) 3.79 Â± 0.62   1.0    5.0    1/100\n",
      "Completeness (1-5)        3.18 Â± 0.80   1.0    5.0    9/100\n",
      "Coherence (1-5)           4.60 Â± 1.03   1.0    5.0    85/100\n",
      "\n",
      "ðŸ“‹ BASELINE QUALITY INSIGHTS:\n",
      "â€¢ High hallucination (â‰¥4): 6/100 (6.0%)\n",
      "â€¢ Low factual consistency (â‰¤2): 4/100 (4.0%)\n",
      "â€¢ Good completeness (â‰¥4): 20/100 (20.0%)\n",
      "â€¢ Good coherence (â‰¥4): 86/100 (86.0%)\n",
      "\n",
      "ðŸ“Š FOR BASELINE TABLE:\n",
      "Hallucination: 2.37 Â± 0.80\n",
      "Factual Consistency: 3.79 Â± 0.62\n",
      "Completeness: 3.18 Â± 0.80\n",
      "Coherence: 4.60 Â± 1.03\n",
      "\n",
      "ðŸ’¾ Results saved to: flan_t5_judge_results.csv\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "# Run the entire script\n",
    "%run llm_as_a_judge_flant5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc3ee6b-1784-4eb4-8d20-f5a4147619ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
